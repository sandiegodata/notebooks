{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "frontmatter"
    ]
   },
   "source": [
    "show_input: show \n",
    "section: notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metapack module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "%load_ext metapack\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import metapack as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sdipylib.geo import *\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from pkg_resources import get_distribution\n",
    "assert get_distribution('publicdata').version >= '0.1.3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Title"
    ]
   },
   "source": [
    "# Basic CRA Demographics Analysis Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a demonstration of how to combine FFIEC records of business loans with census data and display the data in a variety of type of maps. The demonstration will cover using Metatab and Metapack to access data, creating maps with GeoPandas, and creating zoomable maps with a basemap using folium. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Description"
    ]
   },
   "source": [
    "This demonstration will focus on mapping, so if you'd like a more complete tutorial on using Metapack and Census data, please refer to the [American Community Survey tutorial notebook.](http://kb.sandiegodata.org/notebooks/american-community-survey-demonstration/)\n",
    "\n",
    "First, we'll add a Metatab configuration that defines the references to the data we'll use, which include: \n",
    "\n",
    "* An ACS Table for counts of people by race in tracts in San Diego county\n",
    "* Tract grographic boundaries for San DIego County\n",
    "* A Metapack package for CRA Business loan originations. \n",
    "\n",
    "The  [American Community Survey tutorial notebook.](http://kb.sandiegodata.org/notebooks/american-community-survey-demonstration/) has more information about the structure of the Metatab configuration, and the CRA Loan dataset is available in a friendly form at the [Data Library's data repository](http://data.sandiegodata.org/dataset/ffiec-gov-cra_aggregate_smb-orig).\n",
    "\n",
    "Note that to run this notebook, you will need to install these python packages:\n",
    "\n",
    "```\n",
    "jupyter\n",
    "pandas\n",
    "geopandas\n",
    "matplotlib\n",
    "seaborn\n",
    "publicdata\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%metapack` not found.\n"
     ]
    }
   ],
   "source": [
    "%%metapack\n",
    "\n",
    "    \n",
    "Dataset: cra_mapping\n",
    "Origin: sandiegodata.org\n",
    "Version: 1\n",
    "\n",
    "Section: Contacts\n",
    "Wrangler: Eric Busboom\n",
    "Wrangler.Email: eric@sandiegodata.org\n",
    "Wrangler.Organization: San Diego Regional Data Library\n",
    "  \n",
    "Section: References\n",
    "\n",
    "Reference: censusreporter:B02001/140/05000US06073\n",
    "Reference.Name: B02001\n",
    "Reference.Description: Table B02001: Race, by tract, in San Diego County\n",
    "\n",
    "Reference: censusreportergeo://B02001/140/05000US06073\n",
    "Reference.Name: B02001g\n",
    "Reference.Description: Table B02001: Race, by tract, in San Diego County\n",
    "\n",
    "Reference: \n",
    "Reference.Name: agg_loan_orig\n",
    "Reference.Description: CRA Loan originations, aggregated to tracts.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ShapefileUrl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f43ce944c789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrowgenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappurl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_app_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mB02001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_app_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'censusreporter:B02001/140/05000US06073'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mB02001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_app_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'censusreportergeo://B02001/140/05000US06073'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mB02001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_app_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'censusreporter:B02001/140/05000US06073'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/rowgenerators/appurl/url.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mrowgenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/publicdata/census/censusreporter/url.py\u001b[0m in \u001b[0;36mget_resource\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mrowgenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappurl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapefileUrl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapefileUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ShapefileUrl'"
     ]
    }
   ],
   "source": [
    "from rowgenerators.appurl import parse_app_url\n",
    "B02001 = parse_app_url('censusreporter:B02001/140/05000US06073').generator.dataframe()\n",
    "B02001 = parse_app_url('censusreportergeo://B02001/140/05000US06073').generator.dataframe()\n",
    "B02001 = parse_app_url('censusreporter:B02001/140/05000US06073').generator.dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Processing Data\n",
    "\n",
    "Generally, the first parts of a Notebook should contain all of the data manipulations to get data sets combined, or or create new columns, and the the remainer of the notebook is the analysis. So, we will start by extracting data frames from the Metatab configuration. Recall from the  [American Community Survey tutorial notebook.](http://kb.sandiegodata.org/notebooks/american-community-survey-demonstration/)  that the ``%metatab`` cell creates the ``mt_pkg`` package variable, and from that package we can extract dataframes, for census data, and geoframes for geographic data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The mt_pkg var is created by the %%metatab magic. \n",
    "# The B02001 and B02001g frames have the same data, but B02001 is a CensusDataFrame and B02001g is a GeoDataFrame\n",
    "B02001 = mt_pkg.reference('B02001').dataframe().set_index('geoid')\n",
    "B02001g = mt_pkg.reference('B02001g').geoframe().set_index('geoid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the URL of the data frame ``B02001`` is special ( the ``censusreporter:`` scheme is defined in the ``publicdata`` package ) the resulting dataframe is of type ``publicdata.censusreporter.dataframe.CensusDataFrame``, it has a lot of special features, including a ``.title`` property that expands the column names to be more sensible. This view makes it easier to figure out what columns to incorporate in later analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B02001.titles.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we're going to create new variables for \"Minority\" and \"Non Minority\" where \"Non Minority\" is defined as White and Asian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B02001['white_asian'], B02001['white_asian_m90'] = B02001.sum_m('B02001002', 'B02001005')\n",
    "B02001['minority'] = B02001.B02001001 - B02001.white_asian\n",
    "B02001['non_min_r'], B02001['non_min_r_m90'] = B02001.ratio('white_asian', 'B02001001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loan data, let's drop all of the records that are nulls, select only tract records,  and select only the year 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans_pkg = mp.open_package('metapack+http://library.metatab.org/ffiec.gov-cra_aggregate_smb-orig-4.csv#sb_agg_loan_orig')\n",
    "loans_r = loans_pkg.default_resource\n",
    "loans = loans_r.read_csv()\n",
    "\n",
    "loans = loans.dropna(subset=['geoid']).dropna(subset=['tract']).set_index('geoid')\n",
    "\n",
    "# Note! Only one Year!\n",
    "loans = loans[loans.year == 2015]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loans_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-503a039a8247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloans_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loans_r' is not defined"
     ]
    }
   ],
   "source": [
    "loans_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can join the ACS, geographic, and loans dataframes. Previously, they were all given ``geoid`` for an index, so joining them is easy. Once they are joined, we can create some summary and derived columns. Note that the geographic dataset is joined first. This is important, because it means that the final ``df`` will also be a geographic dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = B02001g[['geometry']].join(B02001[['non_min_r']]).join(loans)\n",
    "\n",
    "df['number_loans'] = df.number_lt100 + df.number_100_250 + df.number_250_1m\n",
    "df['total_value'] = df.total_lt100 + df.total_100_250 + df.total_250_1m\n",
    "df['mean_value'] = df.total_value + df.number_loans\n",
    "df['loans_per_pop'] = df.number_loans / B02001.B02001001\n",
    "df['loans_per_min'] = df.number_loans / B02001.minority\n",
    "df['loan_val_per_pop'] = df.total_value / B02001.B02001001\n",
    "df['loan_val_per_min'] = df.total_value / B02001.minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Maps\n",
    "\n",
    "\n",
    "Just as ``Metapack`` and the  ``publicdata`` module worked together to turn the dataset references by the ``censusreporter:`` reference into a special Census data frame, the ``censusreportergeo:`` reference returns a Geopandas dataframe. Geopandas has a built in support for geographic operations, such as creating maps. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matplotlib figure and a single axis, and set the figure size\n",
    "# to 12 inches wide, with the same aspect ratio as the geographic dataframe. This\n",
    "# keeps the map from looking distored. \n",
    "fig, ax = aspect_fig_size(df, 12) \n",
    "\n",
    "_ = df.dropna(subset=['non_min_r'])\n",
    "\n",
    "_.plot(ax=ax, column='non_min_r', cmap='RdYlGn',scheme='fisher_jenks', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdipylib.geo import aspect \n",
    "\n",
    "\n",
    "# In this case, with multiple axes per figure, setting the aspect ratio is more manual\n",
    "w = 6\n",
    "a = max(aspect(_mv),aspect(_lpp))\n",
    "\n",
    "fig = plt.figure(figsize = (2*w, 2*(w/a)))\n",
    "\n",
    "# Doing ax2 first because it has the longer y axis, and want both plots to have the same\n",
    "# y axis\n",
    "ax2= fig.add_subplot(2,2,2)\n",
    "_ = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['loans_per_pop'])\\\n",
    "    .sort_values('loans_per_pop', ascending=False).iloc[:50]\n",
    "_.plot(ax=ax2, column='loans_per_pop', cmap='RdYlGn',scheme='fisher_jenks', legend=True)\n",
    "ax2.set_title(\"Top 50 Tracts By # Loans Per Population\")\n",
    "\n",
    "# subplot(nrows, ncols, plot_number)\n",
    "ax1= fig.add_subplot(2,2,1, sharey=ax2)\n",
    "_ = df.dropna(subset=['mean_value']).sort_values('mean_value', ascending=False).iloc[:50]\n",
    "\n",
    "_.plot(ax=ax1, column='mean_value', cmap='RdYlGn',scheme='fisher_jenks', legend=True)\n",
    "ax1.set_title(\"Top 50 Tracts By Mean Loan Value\")\n",
    "\n",
    "ax3= fig.add_subplot(2,2,3, sharey=ax2)\n",
    "_ = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['loan_val_per_pop'])\n",
    "_ = _[_.loan_val_per_pop>3]\n",
    "_.plot(ax=ax3, column='loan_val_per_pop', cmap='RdYlGn',scheme='fisher_jenks', legend=True)\n",
    "ax3.set_title(\"Tracts with > $3 Loan Value Per Pop\")\n",
    "\n",
    "ax4= fig.add_subplot(2,2,4, sharey=ax2)\n",
    "_ = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['loan_val_per_min'])\n",
    "_ = _[_.loan_val_per_min>24]\n",
    "_.plot(ax=ax4, column='loan_val_per_min', cmap='RdYlGn',scheme='fisher_jenks', legend=True)\n",
    "ax4.set_title(\"Tracts with > $24 Loan Value Per Minority\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas mapping is really easy, but it is hard to tell where the tracts are, because there is no base map. The folium module links Geopandas and Leaflet, and lets us put choropleth maps on a scrollable, zoomable map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['loan_val_per_pop'])\n",
    "_ = _[_.loan_val_per_pop>3]\n",
    "folium_map(_,'loan_val_per_pop', zoom_start=10, fill_color='YlGn', fill_opacity=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['loans_per_pop'])\n",
    "_ = _.sort_values('loans_per_pop', ascending=False).iloc[:100] # don't exceed notebooks IOPub data rate\n",
    "#_ = _[_.loan_val_per_pop>3]\n",
    "folium_map(_,'loans_per_pop', zoom_start=10, fill_color='YlGn', fill_opacity=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on Minority Areas with Radius Searches\n",
    "\n",
    "Next, we'll locate an area with a high portion of minorities and focus on the nearby area. By sorting on the ``non_min_r`` ( Non-minority ratio ) and selecting the bottom 20 values, we can union the tracts, find the center, and then use that as the center for a minority cluster. \n",
    "\n",
    "Using Geopandas, we can use plot the bottom 20 tracts to get a quick view of the area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 30 highest minority areas and plot as a seperate set. They are fairly \n",
    "# geographically clustered\n",
    "_ = df.sort_values('non_min_r').iloc[:20]\n",
    "_.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the distance from the minority center to the centroid of all other tracts. We'll use this value to constrain the radius search. The resulting distances are in meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the center point of the high-minority areas. The unary_union is required\n",
    "# because the subsequence operations work on individual shapes, so we have to join the shapes first. \n",
    "minority_center = df.sort_values('non_min_r').iloc[:20].unary_union.convex_hull.centroid\n",
    "\n",
    "#\n",
    "# Then compute the distance of each other the remaining tracts to \n",
    "# the high minority centroid. \n",
    "df['minr_dist_deg'] = df.geometry.distance(minority_center)\n",
    "\n",
    "import pyproj\n",
    "from functools import partial\n",
    "\n",
    "geod = pyproj.Geod(ellps='WGS84')\n",
    "def geodetic_dist(point1, region2):\n",
    "    \"\"\"Returns the distance between a point and the centroid of a region in meters\"\"\"\n",
    "    point2 = region2.centroid\n",
    "    angle1,angle2,distance = geod.inv(point1.x, point1.y, point2.x, point2.y)\n",
    "    return distance\n",
    "\n",
    "# Note that this distance will tend to exclude large tracts, because the centroids are relatively farther away. \n",
    "df['minr_dist_m'] =df.geometry.apply(partial(geodetic_dist, minority_center))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we just need to constrain the ``minr_dist_m`` to get our cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_areas = df[ df.minr_dist_m < 7000].dropna(subset=['non_min_r'])\n",
    "min_areas = min_areas.dropna(subset=['non_min_r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting is easy, as before, but this time we'll also add a large blue dot to marl the location of the centroid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = aspect_fig_size(min_areas, 15)\n",
    "\n",
    "min_areas.plot(ax=ax, column='non_min_r', cmap='RdYlGn',scheme='fisher_jenks', legend=True)\n",
    "\n",
    "\n",
    "# Plot the minority centroid point, with a bit of a buffer to make it larger\n",
    "import descartes \n",
    "circle = minority_center.buffer(.002)\n",
    "ax.add_patch(descartes.PolygonPatch(circle, fc='blue', alpha=0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, it is easier to visualize where this cluster is when it is laid over a street map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium_map(min_areas,'non_min_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
